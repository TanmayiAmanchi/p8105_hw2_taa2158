Homework 2 taa2158
================
Tanmayi Amanchi
2024-09-30

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library (readxl)
library (haven)
library(dplyr)
```

# Problem 1

### Import and clean the NYC Transit CSV.

``` r
nyc_transit = read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv")
nyc_transit = janitor::clean_names(nyc_transit)
```

Select the required columns

``` r
nyc_transit <- nyc_transit %>%
  mutate(routes_served = apply(select(.,route1:route11), 1, function(x) paste(na.omit(x), collapse = ", "))) %>%
  select(line, station_name, station_latitude, station_longitude, entry, vending, entrance_type, ada, routes_served) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

The variables in the nyc_transit data set are line, station_name,
station_longitude, station_latitude, entry, vending, entrance_type, ada,
and routes_served. The cleaning steps performed so far include selecting
only the relevant columns, creating a new variable routes_served that
consolidates information about the routes served at each station, and
converting the entry variable from character strings to logical values.
The resulting data set dimensions are 1,868 × 9. This is considered
tidy, as each variable is represented by a column, each observation is a
row, and each type of observational unit is a table.

### Finding how many distinct stations there are

``` r
distinct_stations <- nrow(nyc_transit %>% distinct(line, station_name))
distinct_stations
```

    ## [1] 465

According to this code, there are 465 distinct stations in New York
City.

### Finding how many are ADA compliant

``` r
ada_compliant_stations <- sum(nyc_transit$ada == TRUE)
ada_compliant_stations
```

    ## [1] 468

According to this code, there are 468 ada compliant stations.

### Proportion of station entrances / exits without vending allow entrance?

``` r
nyc_transit <- nyc_transit %>%
  mutate(vending = ifelse(vending == "YES", TRUE, FALSE)) 

proportion_without_vending <- nyc_transit %>%
  filter(vending == FALSE) %>%                              
  summarise(proportion = mean(entry, na.rm = TRUE)) %>%   
  pull(proportion)

proportion_without_vending
```

    ## [1] 0.3770492

The output of this code gives us 0.3770492. This means that 37.70% of
stations/entrances don’t have a vending allow entrance.

``` r
a_train_stations <- nyc_transit %>%
  filter(routes_served == "A") %>%
  distinct(line, station_name)  

num_a_train_stations <- nrow(a_train_stations)

num_ada_compliant_a_train_stations <- sum(a_train_stations$ada == TRUE, na.rm = TRUE)
```

    ## Warning: Unknown or uninitialised column: `ada`.

``` r
print(num_a_train_stations)  
```

    ## [1] 21

``` r
print(num_ada_compliant_a_train_stations) 
```

    ## [1] 0

21 distinct stations serve the A train. Of the stations that serve the A
train, 0 are ADA compliant.

# Problem 2

### Import, read and clean Mr. Trash Wheel data set

``` r
mr_trash = read_excel("./data/202409 Trash Wheel Collection Data.xlsx", 
                      sheet = "Mr. Trash Wheel",
                      range = "A2:N651") %>%
  janitor::clean_names() %>% 
  mutate(sports_balls = round(sports_balls),
         sports_balls = as.integer(sports_balls),
         type = "mr_trash",
         year = as.numeric(year)
  )
```

### Import, read, clean, and organize the data for Professor Trash Wheel

``` r
professor_trash = read_excel("./data/202409 Trash Wheel Collection Data.xlsx", 
                             sheet = "Professor Trash Wheel",
                             range = "A2:M120") %>% 
  janitor::clean_names() %>% 
  mutate(type = "professor_trash")
```

### Import, read, clean, and organize the data for Gwynnda Trash Wheel

``` r
gwynnda_trash = read_excel("./data/202409 Trash Wheel Collection Data.xlsx", 
                           sheet = "Gwynnda Trash Wheel",
                           range = "A2:L265") %>% 
  janitor::clean_names() %>% 
  mutate(type = "gwynnda_trash")
```

### Combine to produce a single tidy data set

``` r
trash_combine = bind_rows(mr_trash, professor_trash, gwynnda_trash) %>% 
  relocate(type)
```

There are 1030 observations and 15 columns in the resulting data set. By
using the print function, we can see the first couple rows of the
combined data set:

``` r
print(trash_combine)
```

    ## # A tibble: 1,030 × 15
    ##    type  dumpster month  year date                weight_tons volume_cubic_yards
    ##    <chr>    <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ##  1 mr_t…        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ##  2 mr_t…        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ##  3 mr_t…        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ##  4 mr_t…        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ##  5 mr_t…        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ##  6 mr_t…        6 May    2014 2014-05-20 00:00:00        2.71                 13
    ##  7 mr_t…        7 May    2014 2014-05-21 00:00:00        1.91                  8
    ##  8 mr_t…        8 May    2014 2014-05-28 00:00:00        3.7                  16
    ##  9 mr_t…        9 June   2014 2014-06-05 00:00:00        2.52                 14
    ## 10 mr_t…       10 June   2014 2014-06-11 00:00:00        3.76                 18
    ## # ℹ 1,020 more rows
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>

### Finding the total weight of trash collected by Professor Trash Wheel and the total number of cigarette butts collected by Gwynnda in June of 2022

``` r
prof_weight = 
  trash_combine %>% 
  filter(type == "professor_trash") %>% 
  pull(weight_tons) %>% 
  sum()

gwyn_cigarette = 
  trash_combine %>% 
  filter(type == "gwynnda_trash",
         year == 2022,
         month == "June") %>% 
  pull(cigarette_butts) %>% 
  sum()
```

The total weight of trash collected by Professor Trash Wheel is 246.74
tons. The total number of cigarette butts collected by Gwynnda in June
of 2022 is 18120.

# Problem 3

### Import, clean, tidy, and wrangle bakes results and bake csv

``` r
bakers = read_csv("./data/gbb_datasets/bakers.csv") %>% 
  janitor::clean_names() %>% 
  mutate(baker_first_name = sub(" .*", "", baker_name)
         )
```

``` r
bakes = read_csv("./data/gbb_datasets/bakes.csv", na = c("NA", "N/A", "UNKNOWN", "Unknown", "")) %>% 
  janitor::clean_names() %>% 
  mutate(baker = ifelse(baker == "\"Jo\"", "Jo", baker)) %>% 
  rename(baker_first_name = baker) %>% 
  arrange(baker_first_name)
```

``` r
results = read_csv("./data/gbb_datasets/results.csv",skip = 2) %>% 
  janitor::clean_names() %>% 
  rename(baker_first_name = baker) %>% 
  arrange(baker_first_name) %>% 
  drop_na(result)
```

When cleaning the `bakers`, `bake`, and `results` csv files, I decided
to record all non-numerical and unknown characters as NA. The baker
named Jo in the bakes csv was converted into Jo in order to match the
name in the other data sets.This was also done to change `baker` into
`baker_first_name` in order to maintain correctness across all datasets.
Lastly, bakers are ordered alphabetically. Looking at the results csv I
also notice how the eliminated bakers have NA after they are eliminated,
so this should be dropped from the data set.

### Organize bakers and bake datasets

``` r
baker_bake = left_join(bakers, bakes, join_by(baker_first_name, series))

baker_joined = full_join(baker_bake, results, join_by(baker_first_name, series, episode)) %>% 
  group_by(baker_first_name, series) %>% 
  fill(baker_name:hometown) %>% 
  ungroup() %>% 
  arrange(baker_first_name) %>% 
  drop_na(episode)
```

The `bakes` and `bake` data set are combines by the baker’s first names.
This file called `baker_bake` was combined with the results csv by
baker’s first name, series, and episode information. The resulting file
with information from bakes, bake, and results is called `baker_joined`
This data set has removed NA’s from episode information since every
baker does not have information for that.

### View individual data sets using anti_join

``` r
anti_join(bakers,baker_joined,join_by(baker_first_name, series))
```

    ## # A tibble: 0 × 6
    ## # ℹ 6 variables: baker_name <chr>, series <dbl>, baker_age <dbl>,
    ## #   baker_occupation <chr>, hometown <chr>, baker_first_name <chr>

``` r
anti_join(bakes, baker_joined,join_by(baker_first_name, series, episode))
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker_first_name <chr>,
    ## #   signature_bake <chr>, show_stopper <chr>

``` r
anti_join(results, baker_joined, join_by(baker_first_name, series, episode))
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker_first_name <chr>,
    ## #   technical <dbl>, result <chr>

### Final resulting dataset

``` r
baker_final = baker_joined %>% 
  select(baker_first_name, baker_name, baker_age, baker_occupation, hometown, series, episode, technical, result, signature_bake, show_stopper) %>% 
  rename(baker_full_name = baker_name)

baker_final %>% 
write_csv("./data/gbb_datasets/baker_final.csv")
```

In the \`baker_final data set, the variables are organized in a
meaningful manner with basic information about the baker such as name,
age, occupation, performance, series, and episodes. This file is also
exported and saved as a csv to my data folder.

We can use the print function to see first couple rows of the
baker_final data set

``` r
print(baker_final)
```

    ## # A tibble: 718 × 11
    ##    baker_first_name baker_full_name baker_age baker_occupation  hometown  series
    ##    <chr>            <chr>               <dbl> <chr>             <chr>      <dbl>
    ##  1 Ali              Ali Imdad              25 Charity worker    Saltley,…      4
    ##  2 Ali              Ali Imdad              25 Charity worker    Saltley,…      4
    ##  3 Ali              Ali Imdad              25 Charity worker    Saltley,…      4
    ##  4 Ali              Ali Imdad              25 Charity worker    Saltley,…      4
    ##  5 Alice            Alice Fevronia         28 Geography teacher Essex         10
    ##  6 Alice            Alice Fevronia         28 Geography teacher Essex         10
    ##  7 Alice            Alice Fevronia         28 Geography teacher Essex         10
    ##  8 Alice            Alice Fevronia         28 Geography teacher Essex         10
    ##  9 Alice            Alice Fevronia         28 Geography teacher Essex         10
    ## 10 Alice            Alice Fevronia         28 Geography teacher Essex         10
    ## # ℹ 708 more rows
    ## # ℹ 5 more variables: episode <dbl>, technical <dbl>, result <chr>,
    ## #   signature_bake <chr>, show_stopper <chr>

The baker_final data set has 718 rows and 11 columns.

### Star baker season 5 to season 10

``` r
baker_final %>% 
  select(series, result, baker_first_name) %>% 
  filter(series >= 5, series <= 10, result %in% c("WINNER", "STAR BAKER")) %>%
  mutate(result = case_match(result, "WINNER" ~ "Winner", "STAR BAKER" ~ "Star Baker")) %>% 
  arrange(series, result) %>% 
  distinct() %>% 
  pivot_wider(
    names_from = result,
    values_from = baker_first_name,
    values_fn = list
    ) %>% 
  rename(Series = series) %>% 
  knitr::kable()
```

| Series | Star Baker                                   | Winner  |
|-------:|:---------------------------------------------|:--------|
|      5 | Chetna , Kate , Luis , Nancy , Richard       | Nancy   |
|      6 | Ian , Marie , Mat , Nadiya, Tamal            | Nadiya  |
|      7 | Andrew , Benjamina, Candice , Jane , Tom     | Candice |
|      8 | Julia , Kate , Liam , Sophie, Stacey, Steven | Sophie  |
|      9 | Briony , Dan , Kim-Joy, Manon , Rahul , Ruby | Rahul   |
|     10 | Alice , Henry , Michael , Michelle, Steph    | David   |

Filter to see star bakers, and winners

``` r
baker_final %>% 
  select(series, result, baker_first_name) %>% 
  filter(series >= 5, series <= 10,
         result %in% c("WINNER", "STAR BAKER")) %>%
  arrange(baker_first_name) %>% 
  distinct() %>% 
  knitr::kable()
```

| series | result     | baker_first_name |
|-------:|:-----------|:-----------------|
|     10 | STAR BAKER | Alice            |
|      7 | STAR BAKER | Andrew           |
|      7 | STAR BAKER | Benjamina        |
|      9 | STAR BAKER | Briony           |
|      7 | STAR BAKER | Candice          |
|      7 | WINNER     | Candice          |
|      5 | STAR BAKER | Chetna           |
|      9 | STAR BAKER | Dan              |
|     10 | WINNER     | David            |
|     10 | STAR BAKER | Henry            |
|      6 | STAR BAKER | Ian              |
|      7 | STAR BAKER | Jane             |
|      8 | STAR BAKER | Julia            |
|      5 | STAR BAKER | Kate             |
|      8 | STAR BAKER | Kate             |
|      9 | STAR BAKER | Kim-Joy          |
|      8 | STAR BAKER | Liam             |
|      5 | STAR BAKER | Luis             |
|      9 | STAR BAKER | Manon            |
|      6 | STAR BAKER | Marie            |
|      6 | STAR BAKER | Mat              |
|     10 | STAR BAKER | Michael          |
|     10 | STAR BAKER | Michelle         |
|      6 | STAR BAKER | Nadiya           |
|      6 | WINNER     | Nadiya           |
|      5 | STAR BAKER | Nancy            |
|      5 | WINNER     | Nancy            |
|      9 | STAR BAKER | Rahul            |
|      9 | WINNER     | Rahul            |
|      5 | STAR BAKER | Richard          |
|      9 | STAR BAKER | Ruby             |
|      8 | STAR BAKER | Sophie           |
|      8 | WINNER     | Sophie           |
|      8 | STAR BAKER | Stacey           |
|     10 | STAR BAKER | Steph            |
|      8 | STAR BAKER | Steven           |
|      6 | STAR BAKER | Tamal            |
|      7 | STAR BAKER | Tom              |

After organizing the baker_final data set to see the winners and star
bakers, we can see who won each season from season 5 to 10. It was
interesting to see that many of the star bakers ultimately became the
winner at the end of the season. The winner of season 10, however won
the competition but did not receive a star baker. Therefore, we cannot
make strong judgments from this information but we can make inferences.

### Viewership

``` r
viewers = read_csv("./data/gbb_datasets/viewers.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    cols = series_1:series_10,
    names_to = "series",
    values_to = "viewership",
    names_prefix = "series_"
  ) %>% 
  mutate(series = as.numeric(series)) %>% 
  relocate(series) %>% 
  arrange(series)

head(viewers, 10)
```

    ## # A tibble: 10 × 3
    ##    series episode viewership
    ##     <dbl>   <dbl>      <dbl>
    ##  1      1       1       2.24
    ##  2      1       2       3   
    ##  3      1       3       3   
    ##  4      1       4       2.6 
    ##  5      1       5       3.03
    ##  6      1       6       2.75
    ##  7      1       7      NA   
    ##  8      1       8      NA   
    ##  9      1       9      NA   
    ## 10      1      10      NA

``` r
viewers %>% 
  filter(series == 1) %>% 
  pull(viewership) %>% 
  mean(, na.rm = TRUE)
```

    ## [1] 2.77

``` r
viewers %>% 
  filter(series == 5) %>% 
  pull(viewership) %>% 
  mean(, na.rm = TRUE)
```

    ## [1] 10.0393

The average viewership in Season 1 is 2.77 and 10.04 in Season 5.
